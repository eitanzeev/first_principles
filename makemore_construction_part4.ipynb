{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Create train, dev/val,test\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "words = open('names.txt', 'r').read().splitlines()\n",
    "random.seed(42)\n",
    "random.shuffle(words)\n",
    "\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i, s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s, i in stoi.items()}\n",
    "\n",
    "#Building the dataset - very similar to the trigram construction but dynamic\n",
    "def prepare_data(data, block_size):\n",
    "\n",
    "    block_size = block_size #alternative for context length\n",
    "\n",
    "    X, Y = [], []\n",
    "\n",
    "    for w in data:\n",
    "\n",
    "        #print(w, '--- word of interest')\n",
    "        context = [0] * block_size #How many characters to consider from the left to the right\n",
    "        for ch in w + '.': #adding end word\n",
    "            \n",
    "            ix = stoi[ch]\n",
    "\n",
    "            X.append(context)\n",
    "            Y.append(ix)\n",
    "\n",
    "            #print(''.join(itos[i] for i in context), '--->', itos[ix])\n",
    "\n",
    "            context = context[1:] + [ix] #context is redefined as a new list and we move the window to the right\n",
    "\n",
    "\n",
    "    X = torch.tensor(X)\n",
    "    Y = torch.tensor(Y)\n",
    "\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_limit = int(0.8*len(words))\n",
    "dev_limit = int(0.9*len(words))\n",
    "block_size = 3\n",
    "\n",
    "Xtr, Ytr = prepare_data(words[:train_limit], block_size = block_size)\n",
    "Xdev, Ydev = prepare_data(words[train_limit:dev_limit], block_size = block_size)\n",
    "Xtest, Ytest = prepare_data(words[dev_limit:], block_size = block_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to the actual challenges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility function we will use later when comparing manual gradients to PyTorch gradients\n",
    "def cmp(s, dt, t):\n",
    "  ex = torch.all(dt == t.grad).item()\n",
    "  app = torch.allclose(dt, t.grad)\n",
    "  maxdiff = (dt - t.grad).abs().max().item()\n",
    "  print(f'{s:15s} | exact: {str(ex):5s} | approximate: {str(app):5s} | maxdiff: {maxdiff}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4137\n"
     ]
    }
   ],
   "source": [
    "n_embd = 10 # the dimensionality of the character embedding vectors\n",
    "n_hidden = 64 # the number of neurons in the hidden layer of the MLP\n",
    "vocab_size = len(stoi.keys())\n",
    "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
    "C  = torch.randn((vocab_size, n_embd),            generator=g)\n",
    "# Layer 1\n",
    "W1 = torch.randn((n_embd * block_size, n_hidden), generator=g) * (5/3)/((n_embd * block_size)**0.5)\n",
    "b1 = torch.randn(n_hidden,                        generator=g) * 0.1 # using b1 just for fun, it's useless because of BN\n",
    "# Layer 2\n",
    "W2 = torch.randn((n_hidden, vocab_size),          generator=g) * 0.1\n",
    "b2 = torch.randn(vocab_size,                      generator=g) * 0.1\n",
    "\n",
    "\n",
    "# BatchNorm parameters\n",
    "bngain = torch.randn((1, n_hidden))*0.1 + 1.0\n",
    "bnbias = torch.randn((1, n_hidden))*0.1\n",
    "\n",
    "\"\"\"\n",
    "    if self.training:\n",
    "      xmean = x.mean(0, keepdim=True) # batch mean\n",
    "      xvar = x.var(0, keepdim=True) # batch variance\n",
    "    else:\n",
    "      xmean = self.running_mean\n",
    "      xvar = self.running_var\n",
    "      \n",
    "    xhat = (x - xmean) / torch.sqrt(xvar + self.eps) # normalize to unit variance\n",
    "    self.out = self.gamma * xhat + self.beta \n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "# Note: I am initializating many of these parameters in non-standard ways\n",
    "# because sometimes initializating with e.g. all zeros could mask an incorrect\n",
    "# implementation of the backward pass.\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
    "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
    "for p in parameters:\n",
    "  p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "n = batch_size # a shorter variable also, for convenience\n",
    "# construct a minibatch\n",
    "ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
    "Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 10])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C[Xb].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the loss with autograd: 3.3577394485473633\n"
     ]
    }
   ],
   "source": [
    "# forward pass, \"chunkated\" into smaller steps that are possible to backward one at a time\n",
    "\n",
    "emb = C[Xb] # embed the characters into vectors\n",
    "embcat = emb.view(emb.shape[0], -1) # concatenate the vectors\n",
    "\n",
    "# Linear layer 1\n",
    "hprebn = embcat @ W1 + b1 # hidden layer pre-activation\n",
    "\n",
    "\n",
    "# BatchNorm layer\n",
    "bnmeani = 1/n*hprebn.sum(0, keepdim=True)\n",
    "bndiff = hprebn - bnmeani\n",
    "bndiff2 = bndiff**2\n",
    "bnvar = 1/(n-1)*(bndiff2).sum(0, keepdim=True) # note: Bessel's correction (dividing by n-1, not n)\n",
    "bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "bnraw = bndiff * bnvar_inv\n",
    "hpreact = bngain * bnraw + bnbias #self.gamma *xhat + self.beta\n",
    "\n",
    "# Non-linearity\n",
    "h = torch.tanh(hpreact) # hidden layer\n",
    "\n",
    "# Linear layer 2\n",
    "logits = h @ W2 + b2 # output layer\n",
    "\n",
    "\n",
    "# cross entropy loss (same as F.cross_entropy(logits, Yb), except this time it is explicit)\n",
    "logit_maxes = logits.max(1, keepdim=True).values\n",
    "norm_logits = logits - logit_maxes # subtract max for numerical stability\n",
    "counts = norm_logits.exp()\n",
    "counts_sum = counts.sum(1, keepdims=True)\n",
    "counts_sum_inv = counts_sum**-1 # if I use (1.0 / counts_sum) instead then I can't get backprop to be bit exact...\n",
    "probs = counts * counts_sum_inv #be careful of broadcasting\n",
    "logprobs = probs.log()\n",
    "loss = -logprobs[range(n), Yb].mean()\n",
    "\n",
    "# PyTorch backward pass\n",
    "for p in parameters:\n",
    "  p.grad = None\n",
    "for t in [logprobs, probs, counts, counts_sum, counts_sum_inv, # afaik there is no cleaner way\n",
    "          norm_logits, logit_maxes, logits, h, hpreact, bnraw,\n",
    "         bnvar_inv, bnvar, bndiff2, bndiff, hprebn, bnmeani,\n",
    "         embcat, emb]:\n",
    "  t.retain_grad()\n",
    "loss.backward()\n",
    "print(f\"This is the loss with autograd: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logprobs[range(n), Yb].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes of counts:torch.Size([32, 27]) and counts_sum_inv:torch.Size([32, 1])\n",
      "       are different implying broadcasting.\n"
     ]
    }
   ],
   "source": [
    "#The case of counts_sum_inv is tricky. \n",
    "print(f\"\"\"Shapes of counts:{counts.shape} and counts_sum_inv:{counts_sum_inv.shape}\n",
    "       are different implying broadcasting.\"\"\")\n",
    "\n",
    "#With broadcasting we need to make sure we sum along the same broadcast axis (that used in summing)\n",
    "\n",
    "#Hence we use (counts * dprobs).sum(1, keepdim = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nc = a * b but with tensors:\\n#a[3x3] * b[3,1]\\na11*b1, a12 *b1, a13 *b1\\na21 *b2, a22 * b2, a23*b2\\na31 * b3, a32 * b3, a33*b3\\n\\n\\n'"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "c = a * b but with tensors:\n",
    "#a[3x3] * b[3,1]\n",
    "a11*b1, a12 *b1, a13 *b1\n",
    "a21 *b2, a22 * b2, a23*b2\n",
    "a31 * b3, a32 * b3, a33*b3\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Warm up for exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 64]),\n",
       " torch.Size([32, 30]),\n",
       " torch.Size([30, 64]),\n",
       " torch.Size([64]))"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hprebn.shape,embcat.shape, W1.shape, b1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprobs        | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "probs           | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts_sum_inv  | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "dcounts_sum     | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "dcounts         | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "dnorm_logits    | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "dlogit_maxes    | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "dlogits         | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "dh              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "dW2             | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "db2             | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "dhpreact        | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "dbngain         | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "dbnraw          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "dbnbias         | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "dbnvar_inv      | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "dbnvar          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "dbndiff2        | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "dbndiff         | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnmeani         | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "dhprebn         | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "dembcat         | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "dW1             | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "db1             | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "demb            | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "#loss = -logprobs[range(n), Yb].mean()\n",
    "dlogprobs = torch.zeros_like(logprobs)\n",
    "dlogprobs[range(n), Yb] = -(n**-1) #mean = sum()/n_samples\n",
    "\n",
    "\n",
    "#logprobs = probs.log()\n",
    "dprobs = probs**-1 * dlogprobs\n",
    "\n",
    "#dcounts_sum_inv\n",
    "#probs = counts * counts_sum_inv #be careful of broadcasting, check what dcounts_sum_inv should be!\n",
    "dcounts_sum_inv = (counts * dprobs).sum(1, keepdims = True)\n",
    "\n",
    "dcounts_sum = dcounts_sum_inv * -1 * (counts_sum**-2)\n",
    "##counts is used in multiple operations\n",
    "#probs = counts * counts_sum_inv #be careful of broadcasting\n",
    "#counts_sum = counts.sum(1, keepdims=True)\n",
    "#counts_sum_inv = counts_sum**-1\n",
    "\n",
    "dcounts = (counts_sum_inv * dprobs) #will broadcast\n",
    "sample = dcounts_sum * torch.ones_like(counts)\n",
    "dcounts += sample \n",
    "\n",
    "#dnorm_logits\n",
    "#counts = norm_logits.exp()\n",
    "dnorm_logits = dcounts * norm_logits.exp()\n",
    "\n",
    "#norm_logits = logits - logit_maxes # subtract max for numerical stability\n",
    "#result of reverse broadcasting where gradients are branched from separate row values and flow to one single b\n",
    "dlogit_maxes = -1 * dnorm_logits.sum(1, keepdim = True) \n",
    "\n",
    "\n",
    "#dlogits \n",
    "#logits.max(1, keepdim=True).values\n",
    "#logits.max() returns (maximum value, position of maximum value). Can use indexing to get position\n",
    "dlogits = F.one_hot(logits.max(1).indices, num_classes = logits.shape[1]) * dlogit_maxes\n",
    "dlogits += 1 * dnorm_logits\n",
    "\n",
    "\n",
    "#dh logits = h@ W2 + b2\n",
    "dh = dlogits@W2.T\n",
    "\n",
    "#dW2 logits = h@W2 + b2\n",
    "dW2 = h.T @ dlogits\n",
    "\n",
    "#db2 logits = h@W2 + b2\n",
    "db2 = dlogits.sum(0)\n",
    "\n",
    "#h = torch.tanh(hpreact) # hidden layer\n",
    "dhpreact = (1-torch.tanh(hpreact)**2)*dh\n",
    "\n",
    "#hpreact = bngain * bnraw + bnbias #self.gamma *xhat + self.beta\n",
    "dbngain = (bnraw*dhpreact).sum(0, keepdim = True) #element wise multiplication!\n",
    "dbnraw = bngain*dhpreact\n",
    "dbnbias = 1 * dhpreact.sum(0, keepdim = True)\n",
    "\n",
    "#bnraw = bndiff * bnvar_inv\n",
    "dbnvar_inv = (bndiff * dbnraw).sum(0, keepdim = True)\n",
    "\n",
    "#bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "dbnvar = dbnvar_inv * (-0.5*(bnvar+1e-5)**-1.5)\n",
    "\n",
    "#bndiff2 = bndiff**2\n",
    "dbndiff2 = dbnvar * (1/(n-1))\n",
    "\n",
    "#dbndiff\n",
    "dbndiff = dbnraw*bnvar_inv\n",
    "dbndiff += dbndiff2 * (2*bndiff)\n",
    "\n",
    "\n",
    "#bndiff = hprebn - bnmeani\n",
    "dbnmeani = -dbndiff.sum(0, keepdim = True)\n",
    "\n",
    "#dhprebn - bnmeani = 1/n*hprebn.sum(0, keepdim=True)\n",
    "#bndiff = hprebn - bnmeani\n",
    "dhprebn = 1*dbndiff #first branch\n",
    "sample = (torch.ones_like(hprebn) * (1/n)) #We need to replicate gradient scaling (1/n) across all of the samples\n",
    "dhprebn += sample * dbnmeani\n",
    "\n",
    "#dembcat\n",
    "dembcat = dhprebn@W1.T\n",
    "#dW1\n",
    "dW1 = embcat.T@dhprebn\n",
    "\n",
    "#db1\n",
    "db1 = dhprebn.sum(0)\n",
    "\n",
    "#demb\n",
    "#Remember you are \"undoing\" the transformation on dembcat, not demb\n",
    "demb = dembcat.view(emb.shape[0], 3, -1) #embcat = emb.view(emb.shape[0], -1)\n",
    "\n",
    "cmp('logprobs', dlogprobs, logprobs)\n",
    "cmp('probs', dprobs, probs)\n",
    "cmp('counts_sum_inv', dcounts_sum_inv, counts_sum_inv)\n",
    "cmp('dcounts_sum', dcounts_sum, counts_sum)\n",
    "cmp('dcounts', dcounts, counts)\n",
    "cmp('dnorm_logits', dnorm_logits, norm_logits)\n",
    "cmp('dlogit_maxes', dlogit_maxes, logit_maxes)\n",
    "cmp('dlogits',dlogits, logits)\n",
    "cmp('dh', dh, h)\n",
    "cmp('dW2', dW2, W2)\n",
    "cmp('db2',db2, b2)\n",
    "cmp('dhpreact', dhpreact, hpreact)\n",
    "cmp('dbngain', dbngain, bngain)\n",
    "cmp('dbnraw', dbnraw, bnraw)\n",
    "cmp('dbnbias', dbnbias, bnbias)\n",
    "cmp('dbnvar_inv', dbnvar_inv, bnvar_inv)\n",
    "cmp('dbnvar', dbnvar, bnvar)\n",
    "cmp('dbndiff2',dbndiff2, bndiff2)\n",
    "cmp('dbndiff',dbndiff,bndiff )\n",
    "cmp('bnmeani', dbnmeani, bnmeani)\n",
    "cmp('dhprebn',dhprebn, hprebn)\n",
    "cmp('dembcat', dembcat, embcat)\n",
    "cmp('dW1', dW1, W1)\n",
    "cmp('db1', db1, b1)\n",
    "cmp('demb', demb, emb)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprobs        | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "probs           | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts_sum_inv  | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts_sum      | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "norm_logits     | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "____________________________\n",
      "Norm logits shapetorch.Size([32, 27]), Logits shape: torch.Size([32, 27]), Logit maxes shape: torch.Size([32, 1])\n",
      "logit_maxes     | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "_______________________\n",
      "logits          | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Exercise 1: backprop through the whole thing manually, \n",
    "# backpropagating through exactly all of the variables \n",
    "# as they are defined in the forward pass above, one by one\n",
    "\n",
    "dlogprobs = torch.zeros_like(logprobs) #We only care about the gradients used in calculating loss which are the 32 character representations\n",
    "dlogprobs[range(n), Yb] =  -(n**-1)\n",
    "cmp('logprobs', dlogprobs, logprobs)\n",
    "\n",
    "\n",
    "dprobs = dlogprobs*probs**-1\n",
    "cmp('probs', dprobs, probs)\n",
    "\n",
    "dcounts_sum_inv = (counts*dprobs).sum(1, keepdim= True) #we have to sum along here to match the dimensions of counts_sum_inv\n",
    "cmp('counts_sum_inv', dcounts_sum_inv, counts_sum_inv)\n",
    "\n",
    "dcounts_sum = (-1* counts_sum**-2) * dcounts_sum_inv\n",
    "cmp('counts_sum', dcounts_sum, counts_sum)\n",
    "\n",
    "\n",
    "##Counts is tricky because we need to approach the derivative from both sides of the graph\n",
    "dcounts = (counts_sum_inv * dprobs) #broadcasting will expand counts_sum_inv automatically. We don't need to worry about the derivatives\n",
    "#dcounts should be [32,27]\n",
    "\n",
    "\n",
    "# We need to be careful here! Check the sizes of dcounts_sum and the first branch of dcounts!\n",
    "#We want to add dcounts_sum to dcounts but we need to make sure we that we match the size so we repeat it 27 times use torch.ones_like()\n",
    "#  Make sure to double count\n",
    "sample = torch.ones_like(counts)\n",
    "sample = dcounts_sum * sample\n",
    "dcounts += sample\n",
    "cmp('counts', dcounts, counts)\n",
    "\n",
    "#Include the chain rule\n",
    "dnorm_logits = norm_logits.exp() * dcounts\n",
    "cmp('norm_logits', dnorm_logits, norm_logits)\n",
    "\n",
    "\n",
    "print(\"____________________________\")\n",
    "print(f\"Norm logits shape{norm_logits.shape}, Logits shape: {logits.shape}, Logit maxes shape: {logit_maxes.shape}\")\n",
    "\n",
    "\n",
    "\"\"\"There is broadcasting with the minus at logits - logits_max\n",
    "\n",
    "c11 c12 c13 = a11 a12 a13        b1\n",
    "c21 c22 c23 = a21 a22 a23    -   b2\n",
    "c31 c32 c33 = a31 a32 a33        b3\n",
    "\n",
    "c32 = a32 - b3\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "dlogit_maxes = (-1 *  dnorm_logits.sum(1, keepdim = True))#keepdim not to destroy dimensions\n",
    "cmp('logit_maxes', dlogit_maxes, logit_maxes)\n",
    "\n",
    "print(\"_______________________\")\n",
    "\n",
    "#Logits is complicated because there are two streams one through logit_maxes and the other through logits!\n",
    "dlogits = (1 * dnorm_logits)\n",
    "\n",
    "\"\"\"We need to find the derivative for the maximum values chosen from logits rows \"\"\"\n",
    "dlogits += F.one_hot(logits.max(1).indices, num_classes = logits.shape[1]) * dlogit_maxes\n",
    "\n",
    "#alternative\n",
    "# new_sample = torch.zeros_like(logits)\n",
    "# new_sample[range(n), Yb] = 1.0\n",
    "\n",
    "# dlogits += new_sample * dlogit_maxes\n",
    "cmp('logits', dlogits, logits)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linear Layer 2\n",
    "dh = dlogits @ W2.T #shapes indicate how to match dlogits with W2 and h\n",
    "cmp('h', dh, h)\n",
    "dW2 = h.T @ dlogits\n",
    "cmp('W2', dW2, W2)\n",
    "db2 = dlogits.sum(0)\n",
    "cmp('b2', db2, b2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-linear layer (tanh activation layer for us)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-linearity\n",
    "import math\n",
    "dhpreact = dh * (1.0-torch.tanh(hpreact)**2) #derivative of tanh(a) = 1 - torch.tanh(a)**2\n",
    "cmp('hpreact', dhpreact, hpreact)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch normalization layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnraw.shape, bngain.shape, bnbias.shape,  dhpreact.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnvar_inv.shape, bndiff.shape, bnraw.shape, bnvar.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reference: hpreact = bngain * bnraw + bnbias #self.gamma *xhat + self.beta\n",
    "dbngain = (bnraw * dhpreact).sum(0, keepdim = True) #make sure the shapes match. bngain is 1,64!\n",
    "cmp('bngain', dbngain, bngain)\n",
    "\n",
    "dbnbias = dhpreact.sum(0, keepdim=True)\n",
    "cmp('bnbias', dbnbias, bnbias)\n",
    "\n",
    "dbnraw = dhpreact * bngain #broadcasting should take care of this.\n",
    "cmp('bnraw', dbnraw, bnraw)\n",
    "\n",
    "dbnvar_inv = (bndiff * dbnraw).sum(0, keepdim = True) #check sizes above and see that we have to sum along the first axis\n",
    "cmp('bnvar_inv', dbnvar_inv, bnvar_inv)\n",
    "\n",
    "dbnvar = dbnvar_inv * (-0.5*(bnvar+1e-5)**-1.5)\n",
    "print(dbnvar.shape)\n",
    "cmp('bnvar', dbnvar, bnvar)\n",
    "\n",
    "dbndiff2 = dbnvar * (1/(n-1))\n",
    "cmp('bndiff2', dbndiff2, bndiff2)\n",
    "\n",
    "dbndiff = bnvar_inv * dbnraw #multiple channel 1 coming from bnraw = bndiff * bnvar_inv\n",
    "dbndiff += dbndiff2 * (2*bndiff**1) #multiple channle 2 coming from below\n",
    "\"\"\"Channel 2 - we see that bnvar_inv is also due to bndiff\n",
    "bndiff2 = bndiff**2\n",
    "bnvar = 1/(n-1)*(bndiff2).sum(0, keepdim=True) # note: Bessel's correction (dividing by n-1, not n)\n",
    "bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "bnraw = bndiff * bnvar_inv\n",
    "\"\"\"\n",
    "cmp('bndiff', dbndiff, bndiff)\n",
    "\n",
    "#dbnmeani = hprebn - bnmeani\n",
    "dbnmeani = -dbndiff.sum(0, keepdim = True)\n",
    "cmp('bnmeani', dbnmeani, bnmeani)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C[Xb[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cmp('C', dC, C)\n",
    "\n",
    "dhprebn = 1 * dbndiff #bndiff = hprebn - bnmeani\n",
    "sample = torch.ones_like(hprebn) * dbnmeani #Replicate here to take care of the sum in forward pass :) :) :-)\n",
    "dhprebn += (1/n) * sample #1/n*hprebn.sum(0, keepdim = True), this needs to be reversed broadcasted out\n",
    "cmp('hprebn', dhprebn, hprebn)\n",
    "\n",
    "#Same shapes, no broadcasting necessary\n",
    "dembcat = dhprebn @ W1.T #dlogits @ W1.T from matrix derivatives earlier\n",
    "cmp('embcat', dembcat, embcat)\n",
    "\n",
    "#same shapes, no broadcasting necessary\n",
    "dW1 = embcat.T @ dhprebn #h.T @ dlogits from matrix derivatives earlier\n",
    "cmp('W1', dW1, W1)\n",
    "\n",
    "#Same shapes, no broadcasting necessary\n",
    "db1 = dhprebn.sum(0) #no keepdims because the size of b1 is just torch.tensor([64])\n",
    "cmp('b1', db1, b1)\n",
    "\n",
    "#Remember you are \"undoing\" the transformation on dembcat, not demb\n",
    "demb = dembcat.view(emb.shape[0], 3, -1) #embcat = emb.view(emb.shape[0], -1)\n",
    "cmp('demb', demb, emb)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Gradients are now added back to the look up table providing our embeddings!\n",
    "Remember that gradients from different appearances should sum together at the same embedding representation\n",
    "\"\"\"\n",
    "\n",
    "dC = torch.zeros_like(C)\n",
    "for k in range(Xb.shape[0]):\n",
    "    for j in range(Xb.shape[1]):\n",
    "        ix = Xb[k][j]\n",
    "        dC[ix] += demb[k,j] #multiple occurrences!\n",
    "cmp('C', dC, C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2: Backpropagating through batch normalization like a normal person."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2:\n",
    "backprop through cross_entropy but all in one go\n",
    "to complete this challenge look at the mathematical expression of the loss,\n",
    "take the derivative, simplify the expression, and just write it out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.3577394485473633 diff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# forward pass\n",
    "\n",
    "# before:\n",
    "# logit_maxes = logits.max(1, keepdim=True).values\n",
    "# norm_logits = logits - logit_maxes # subtract max for numerical stability\n",
    "# counts = norm_logits.exp()\n",
    "# counts_sum = counts.sum(1, keepdims=True)\n",
    "# counts_sum_inv = counts_sum**-1 # if I use (1.0 / counts_sum) instead then I can't get backprop to be bit exact...\n",
    "# probs = counts * counts_sum_inv\n",
    "# logprobs = probs.log()\n",
    "# loss = -logprobs[range(n), Yb].mean()\n",
    "\n",
    "# now:\n",
    "loss_fast = F.cross_entropy(logits, Yb)\n",
    "print(loss_fast.item(), 'diff:', (loss_fast - loss).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dlogits         | exact: False | approximate: True  | maxdiff: 6.05359673500061e-09\n"
     ]
    }
   ],
   "source": [
    "#backward pass\n",
    "dlogits = F.softmax(logits,1)\n",
    "dlogits[range(n), Yb] += -1\n",
    "\n",
    "dlogits = dlogits /n #for batchwise averaging of loss!\n",
    "cmp('dlogits', dlogits, logits) #due to numerical stability we don't expect an exact match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.8069,  0.9289, -0.4887,  0.4123, -0.4882,  0.9177, -0.2070,  0.1236,\n",
       "        -0.5415,  0.0259,  0.2146,  0.1743,  0.2257, -0.1262,  0.0882, -0.7816,\n",
       "        -1.1819, -0.4384, -0.7226,  0.5580,  0.3788, -0.3337, -0.1219,  0.7728,\n",
       "         0.7000, -0.2139, -0.3391], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fd23ee5e020>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#showing dlogits\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(logits.detach(), cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fd23fe3fdc0>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#showing dlogits\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(dlogits.detach(), cmap = 'gray')\n",
    "\n",
    "\"\"\"Shows cross-entropy gradient changes\n",
    "Black squares are those correct characters\n",
    "push up on probabilities of correct characters, pulling up on probabilities of incorrect characters\n",
    "This plot is representing where the gradient is very low. Black squares.\n",
    "pushing and pulling on correct and incorrect answers - force is proportional to amount of incorrectness. \n",
    "If we are correct, in our predictions no real push/pull is necessary\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 3 Batch normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "dhprebn = bngain*bnvar_inv/n * (n*dhpreact - dhpreact.sum(0)-n/(n-1) * bnraw*(dhpreact*bnraw).sum(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hbprebn         | exact: False | approximate: True  | maxdiff: 9.313225746154785e-10\n"
     ]
    }
   ],
   "source": [
    "cmp('hbprebn', dhprebn, hprebn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "a-alpha-conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
